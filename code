import glob
import os
import time
import copy
import torch
import shutil
import pandas as pd
from skimage import io, transform
import numpy as np
from PIL import Image
from PIL import ImageEnhance
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms, utils
from torch import nn
from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)
import cv2
from albumentations.pytorch.transforms import ToTensorV2
from torch.autograd import Variable
from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout
from torch.nn.modules.utils import _pair
from torch.optim import Adam, SGD
import torch.nn.functional as F
from PIL import Image
from skimage.color import gray2rgb
from skimage.color import rgb2gray
from torch.nn import Conv2d, Module, Linear, BatchNorm2d, ReLU
from torch.nn.modules.utils import _triple, _pair, _single
from functools import reduce
from torch.autograd import Function
import math
from torch.nn import init
from itertools import repeat
import collections.abc as container_abcs
from torch._jit_internal import Optional
from torch.nn.parameter import Parameter
from torch.nn.modules.module import Module
from scipy.interpolate import interp1d
from torch import tensor
from sklearn.metrics import precision_recall_fscore_support

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

def load_ckp(checkpoint_fpath, model, optimizer):
    """
    checkpoint_path: path to save checkpoint
    model: model that we want to load checkpoint parameters into       
    optimizer: optimizer we defined in previous training
    """
    # load check point
    checkpoint = torch.load(checkpoint_fpath, map_location=device)
    # initialize state_dict from checkpoint to model
    model.load_state_dict(checkpoint['state_dict'])
    # initialize optimizer from checkpoint to optimizer
    optimizer.load_state_dict(checkpoint['optimizer'])
    # initialize valid_loss_min from checkpoint to valid_loss_min
    valid_loss_min = checkpoint['valid_loss_min']
    # return model, optimizer, epoch value, min validation loss 
    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()

def Conv2dSame(in_channels, out_channels, kernel_size, use_bias=True, padding_layer=torch.nn.ReflectionPad2d):
    ka = kernel_size // 2
    kb = ka - 1 if kernel_size % 2 == 0 else ka
    return [
        padding_layer((ka, kb, ka, kb)),
        torch.nn.Conv2d(in_channels, out_channels, kernel_size, bias=use_bias)
    ]

def conv2d_bn(in_channels, filters, kernel_size, padding='same', activation='relu'):
    assert padding == 'same'
    affine = False if activation == 'relu' or activation == 'sigmoid' else True
    sequence = []
    sequence += Conv2dSame(in_channels, filters, kernel_size, use_bias=False)
    sequence += [torch.nn.BatchNorm2d(filters, affine=affine)]
    if activation == "relu":
        sequence += [torch.nn.ReLU()]
    elif activation == "sigmoid":
        sequence += [torch.nn.Sigmoid()]
    elif activation == 'tanh':
        sequence += [torch.nn.Tanh()]
    return torch.nn.Sequential(*sequence)

class ResPathBlock(torch.nn.Module):
    def __init__(self, in_channels, filters):
        super(ResPathBlock, self).__init__()
        self.conv2d_bn1 = conv2d_bn(in_channels, filters, 1, activation=None)
        self.conv2d_bn2 = conv2d_bn(in_channels, filters, 3, activation='relu')
        self.relu = torch.nn.ReLU()
        self.bn = torch.nn.BatchNorm2d(filters)

    def forward(self, inp):
        shortcut = self.conv2d_bn1(inp)
        out = self.conv2d_bn2(inp)
        out = torch.add(shortcut, out)
        out = self.relu(out)
        out = self.bn(out)
        return out


class ResPath(torch.nn.Module):
    def __init__(self, in_channels, filters, length):
        super(ResPath, self).__init__()
        self.first_block = ResPathBlock(in_channels, filters)
        self.blocks = torch.nn.Sequential(*[ResPathBlock(filters, filters) for i in range(length - 1)])

    def forward(self, inp):
        out = self.first_block(inp)
        out = self.blocks(out)
        return out
    
class DOConv2d(Module):
    """
       DOConv2d can be used as an alternative for torch.nn.Conv2d.
       The interface is similar to that of Conv2d, with one exception:
            1. D_mul: the depth multiplier for the over-parameterization.
       Note that the groups parameter switchs between DO-Conv (groups=1),
       DO-DConv (groups=in_channels), DO-GConv (otherwise).
    """
    __constants__ = ['stride', 'padding', 'dilation', 'groups',
                     'padding_mode', 'output_padding', 'in_channels',
                     'out_channels', 'kernel_size', 'D_mul']
    __annotations__ = {'bias': Optional[torch.Tensor]}

    def __init__(self, in_channels, out_channels, kernel_size, D_mul=None, stride=1,
                 padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros'):
        super(DOConv2d, self).__init__()

        kernel_size = _pair(kernel_size)
        stride = _pair(stride)
        padding = _pair(padding)
        dilation = _pair(dilation)

        if in_channels % groups != 0:
            raise ValueError('in_channels must be divisible by groups')
        if out_channels % groups != 0:
            raise ValueError('out_channels must be divisible by groups')
        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}
        if padding_mode not in valid_padding_modes:
            raise ValueError("padding_mode must be one of {}, but got padding_mode='{}'".format(
                valid_padding_modes, padding_mode))
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.dilation = dilation
        self.groups = groups
        self.padding_mode = padding_mode
        self._padding_repeated_twice = tuple(x for x in self.padding for _ in range(2))

        #################################### Initailization of D & W ###################################
        M = self.kernel_size[0]
        N = self.kernel_size[1]
        self.D_mul = M * N if D_mul is None or M * N <= 1 else D_mul
        self.W = Parameter(torch.Tensor(out_channels, in_channels // groups, self.D_mul))
        init.kaiming_uniform_(self.W, a=math.sqrt(5))

        if M * N > 1:
            self.D = Parameter(torch.Tensor(in_channels, M * N, self.D_mul))
            init_zero = np.zeros([in_channels, M * N, self.D_mul], dtype=np.float32)
            self.D.data = torch.from_numpy(init_zero)

            eye = torch.reshape(torch.eye(M * N, dtype=torch.float32), (1, M * N, M * N))
            d_diag = eye.repeat((in_channels, 1, self.D_mul // (M * N)))
            if self.D_mul % (M * N) != 0:  # the cases when D_mul > M * N
                zeros = torch.zeros([in_channels, M * N, self.D_mul % (M * N)])
                self.d_diag = Parameter(torch.cat([d_diag, zeros], dim=2), requires_grad=False)
            else:  # the case when D_mul = M * N
                self.d_diag = Parameter(d_diag, requires_grad=False)
        ##################################################################################################

        if bias:
            self.bias = Parameter(torch.Tensor(out_channels))
            fan_in, _ = init._calculate_fan_in_and_fan_out(self.W)
            bound = 1 / math.sqrt(fan_in)
            init.uniform_(self.bias, -bound, bound)
        else:
            self.register_parameter('bias', None)

    def extra_repr(self):
        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'
             ', stride={stride}')
        if self.padding != (0,) * len(self.padding):
            s += ', padding={padding}'
        if self.dilation != (1,) * len(self.dilation):
            s += ', dilation={dilation}'
        if self.groups != 1:
            s += ', groups={groups}'
        if self.bias is None:
            s += ', bias=False'
        if self.padding_mode != 'zeros':
            s += ', padding_mode={padding_mode}'
        return s.format(**self.__dict__)

    def __setstate__(self, state):
        super(DOConv2d, self).__setstate__(state)
        if not hasattr(self, 'padding_mode'):
            self.padding_mode = 'zeros'

    def _conv_forward(self, input, weight):
        if self.padding_mode != 'zeros':
            return F.conv2d(F.pad(input, self._padding_repeated_twice, mode=self.padding_mode),
                            weight, self.bias, self.stride,
                            _pair(0), self.dilation, self.groups)
        return F.conv2d(input, weight, self.bias, self.stride,
                        self.padding, self.dilation, self.groups)

    def forward(self, input):
        M = self.kernel_size[0]
        N = self.kernel_size[1]
        DoW_shape = (self.out_channels, self.in_channels // self.groups, M, N)
        if M * N > 1:
            ######################### Compute DoW #################
            # (input_channels, D_mul, M * N)
            D = self.D + self.d_diag
            W = torch.reshape(self.W, (self.out_channels // self.groups, self.in_channels, self.D_mul))

            # einsum outputs (out_channels // groups, in_channels, M * N),
            # which is reshaped to
            # (out_channels, in_channels // groups, M, N)
            DoW = torch.reshape(torch.einsum('ims,ois->oim', D, W), DoW_shape)
            #######################################################
        else:
            # in this case D_mul == M * N
            # reshape from
            # (out_channels, in_channels // groups, D_mul)
            # to
            # (out_channels, in_channels // groups, M, N)
            DoW = torch.reshape(self.W, DoW_shape)
        return self._conv_forward(input, DoW)

def conv3x3(in_planes, out_planes, stride=1, groups=1):
    """3x3 convolution with padding"""
    return DOConv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=1, groups=groups, bias=False)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return DOConv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class SEModule(nn.Module):
    def __init__(self, channels, reduction=16):
        super(SEModule, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc1 = DOConv2d(channels, channels // reduction, kernel_size=1, padding=0)
        self.relu = nn.ReLU(inplace=True)
        self.fc2 = DOConv2d(channels // reduction, channels, kernel_size=1, padding=0)
        self.sigmoid = nn.Sigmoid()

    def forward(self, input):
        x = self.avg_pool(input)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        return input * x


class Res2NetBottleneck(nn.Module):
    expansion = 2

    def __init__(self, inplanes, planes, downsample=None, stride=1, scales=4, groups=1, se=False,  norm_layer=None):
        super(Res2NetBottleneck, self).__init__()
        if planes % scales != 0:
            raise ValueError('Planes must be divisible by scales')
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        bottleneck_planes = groups * planes
        self.conv1 = conv1x1(inplanes, bottleneck_planes, stride)
        self.bn1 = norm_layer(bottleneck_planes)
        self.conv2 = nn.ModuleList([conv3x3(bottleneck_planes // scales, bottleneck_planes // scales, groups=groups) for _ in range(scales-1)])
        self.bn2 = nn.ModuleList([norm_layer(bottleneck_planes // scales) for _ in range(scales-1)])
        self.conv3 = conv1x1(bottleneck_planes, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.se = SEModule(planes * self.expansion) if se else None
        self.downsample = downsample
        self.stride = stride
        self.scales = scales

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        xs = torch.chunk(out, self.scales, 1)
        ys = []
        for s in range(self.scales):
            if s == 0:
                ys.append(xs[s])
            elif s == 1:
                ys.append(self.relu(self.bn2[s-1](self.conv2[s-1](xs[s]))))
            else:
                ys.append(self.relu(self.bn2[s-1](self.conv2[s-1](xs[s] + ys[-1]))))
        out = torch.cat(ys, 1)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.se is not None:
            out = self.se(out)

        if self.downsample is not None:
            identity = self.downsample(identity)

        out += identity
        out = self.relu(out)

        return out
    
class PFC(nn.Module):
    def __init__(self,channels, kernel_size=7):
        super(PFC, self).__init__()
        self.input_layer = nn.Sequential(
                    DOConv2d(3, channels, kernel_size, padding = kernel_size // 2),
                    nn.ReLU(inplace=True),
                    nn.BatchNorm2d(channels))
        self.depthwise = nn.Sequential(
                    DOConv2d(channels, channels, kernel_size, groups=channels, padding = kernel_size // 2),
                    nn.ReLU(inplace=True),
                    nn.BatchNorm2d(channels))
        self.pointwise = nn.Sequential(
                    DOConv2d(channels, channels, kernel_size=1),
                    nn.ReLU(inplace=True),
                    nn.BatchNorm2d(channels))
    def forward(self, x):
        x = self.input_layer(x)
        residual = x
        x = self.depthwise(x)
        x += residual
        x = self.pointwise(x)
        return x
    
def double_conv_decode(in_channels, out_channels):
    return nn.Sequential(
        DOConv2d(in_channels, out_channels, kernel_size=3, padding=1),
        nn.BatchNorm2d(out_channels),
        nn.ReLU(inplace=True)
    )

class Unet(nn.Module):
    def __init__(self, groups=1, width=4, scales=4, se=False, norm_layer=None):
        self.inplanes = 16
        super().__init__()
        self.pfc = PFC(16)
        self.dblock1 = self._make_layer(Res2NetBottleneck, 16, 1, scales=scales, groups=groups, se=se, norm_layer=norm_layer)
        self.dblock2 = self._make_layer(Res2NetBottleneck, 32, 1, scales=scales, groups=groups, se=se, norm_layer=norm_layer)
        self.dblock3 = self._make_layer(Res2NetBottleneck, 64, 3, scales=scales, groups=groups, se=se, norm_layer=norm_layer)
        self.dblock4 = self._make_layer(Res2NetBottleneck, 128, 1, scales=scales, groups=groups, se=se, norm_layer=norm_layer)
        self.dblock5 = self._make_layer(Res2NetBottleneck, 256, 1, scales=scales, groups=groups, se=se, norm_layer=norm_layer)
        
        self.dblock6 = self._make_layer(Res2NetBottleneck, 512, 1, scales=scales, groups=groups, se=se, norm_layer=norm_layer)

        self.pool = nn.MaxPool2d(2)
        
        #7
        self.down1_7 = nn.Sequential(
            nn.MaxPool2d(16),
            DOConv2d(32, 128, 3, padding=1)
        )
        self.down2_7 = nn.Sequential(
            nn.MaxPool2d(8),
            DOConv2d(64, 128, 3, padding=1)
        )
        self.down3_7 = nn.Sequential(
            nn.MaxPool2d(4),
            DOConv2d(128, 128, 3, padding=1)
        )
        self.down4_7 = nn.Sequential(
            nn.MaxPool2d(2),
            DOConv2d(256, 128, 3, padding=1),
        )
        self.skip_connect_5_7 = nn.Sequential(
            ResPath(512, 128, 1)
        )
        self.upsample6 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bilinear'),
            DOConv2d(1024, 128, 3, padding=1)
        )
        self.dblock7 = double_conv_decode(128*6, 512)
        #8
        self.down1_8 = nn.Sequential(
            nn.MaxPool2d(8),
            DOConv2d(32, 128, 3, padding=1)
        )
        self.down2_8 = nn.Sequential(
            nn.MaxPool2d(4),
            DOConv2d(64, 128, 3, padding=1)
        )
        self.down3_8 = nn.Sequential(
            nn.MaxPool2d(2),
            DOConv2d(128, 128, 3, padding=1)
        )
        self.skip_connect_4_8 = nn.Sequential(
            ResPath(256, 128, 2)
        )
        self.upsample7_8 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bilinear'),
            DOConv2d(512, 128, 3, padding=1)
        )
        self.upsample6_8 = nn.Sequential(
            nn.Upsample(scale_factor=4, mode='bilinear'),
            DOConv2d(1024, 128, 3, padding=1)
        )
        self.dblock8 = double_conv_decode(128*6, 256)
        #9
        self.down1_9 = nn.Sequential(
            nn.MaxPool2d(4),
            DOConv2d(32, 128, 3, padding=1)
        )
        self.down2_9 = nn.Sequential(
            nn.MaxPool2d(2),
            DOConv2d(64, 128, 3, padding=1)
        )
        self.skip_connect_3_9 = nn.Sequential(
            ResPath(128, 128, 3)
        )
        self.upsample8_9 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bilinear'),
            DOConv2d(256, 128, 3, padding=1)
        )
        self.upsample7_9 = nn.Sequential(
            nn.Upsample(scale_factor=4, mode='bilinear'),
            DOConv2d(512, 128, 3, padding=1)
        )
        self.upsample6_9 = nn.Sequential(
            nn.Upsample(scale_factor=8, mode='bilinear'),
            DOConv2d(1024, 128, 3, padding=1)
        )
        self.dblock9 = double_conv_decode(128*6, 128)
        #10
        self.down1_10 = nn.Sequential(
            nn.MaxPool2d(2),
            DOConv2d(32, 128, 3, padding=1)
        )
        self.skip_connect_2_10 = nn.Sequential(
            ResPath(64, 128, 4)
        )
        self.upsample9_10 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bilinear'),
            DOConv2d(128, 128, 3, padding=1)
        )
        self.upsample8_10 = nn.Sequential(
            nn.Upsample(scale_factor=4, mode='bilinear'),
            DOConv2d(256, 128, 3, padding=1)
        )
        self.upsample7_10 = nn.Sequential(
            nn.Upsample(scale_factor=8, mode='bilinear'), 
            DOConv2d(512, 128, 3, padding=1)
        )
        self.upsample6_10 = nn.Sequential(
            nn.Upsample(scale_factor=16, mode='bilinear'), 
            DOConv2d(1024, 128, 3, padding=1)
        )
        self.dblock10 = double_conv_decode(128*6, 64)
        #11
        self.skip_connect_1_11 = nn.Sequential(
            ResPath(32, 128, 5)
        )
        self.upsample10_11 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bilinear'),
            DOConv2d(64, 128, 3, padding=1)
        )
        self.upsample9_11 = nn.Sequential(
            nn.Upsample(scale_factor=4, mode='bilinear'),
            DOConv2d(128, 128, 3, padding=1)
        )
        self.upsample8_11 = nn.Sequential(
            nn.Upsample(scale_factor=8, mode='bilinear'),
            DOConv2d(256, 128, 3, padding=1)
        )
        self.upsample7_11 = nn.Sequential(
            nn.Upsample(scale_factor=16, mode='bilinear'),
            DOConv2d(512, 128, 3, padding=1)
        )
        self.upsample6_11 = nn.Sequential(
            nn.Upsample(scale_factor=32, mode='bilinear'),
            DOConv2d(1024, 128, 3, padding=1)
        )
        self.dblock11 = double_conv_decode(128*6, 32)

        self.last_layer = DOConv2d(32,1,1)
        self.sigmoid = nn.Sigmoid()
        
    def _make_layer(self, block, planes, blocks, stride=1, scales=4, groups=1, se=False, norm_layer=None):
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, downsample, stride=stride, scales=scales, groups=groups, se=se, norm_layer=norm_layer))
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(block(self.inplanes, planes, scales=scales, groups=groups, se=se, norm_layer=norm_layer))

        return nn.Sequential(*layers)

    def forward(self,x):
        
        x = self.pfc(x)
        
        conv1 = self.dblock1(x)
        x = self.pool(conv1)

        conv2 = self.dblock2(x)
        x = self.pool(conv2)

        conv3 = self.dblock3(x)
        x = self.pool(conv3)

        conv4 = self.dblock4(x)
        x = self.pool(conv4)
        
        conv5 = self.dblock5(x)
        x = self.pool(conv5)
        
        conv6 = self.dblock6(x)
        
        #第7个节点，1 2 3 4 down 5skip 6 up
        c1_7 = self.down1_7(conv1)
        c2_7 = self.down2_7(conv2)
        c3_7 = self.down3_7(conv3)
        c4_7 = self.down4_7(conv4)
        c5_7 = self.skip_connect_5_7(conv5)
        c6_7 = self.upsample6(conv6)
        x = torch.cat([c1_7, c2_7, c3_7, c4_7, c5_7, c6_7], dim=1)
        conv7 = self.dblock7(x)
        #第8个节点，1 2 3 down 4skip 5 6 up
        c1_8 = self.down1_8(conv1)
        c2_8 = self.down2_8(conv2)
        c3_8 = self.down3_8(conv3)
        c4_8 = self.skip_connect_4_8(conv4)
        c7_8 = self.upsample7_8(conv7)
        c6_8 = self.upsample6_8(conv6)
        x = torch.cat([c1_8, c2_8, c3_8, c4_8, c7_8, c6_8], dim=1)
        conv8 = self.dblock8(x)
        #第9个节点，1 2 down 3skip 4 5 6 up
        c1_9 = self.down1_9(conv1)
        c2_9 = self.down2_9(conv2)
        c3_9 = self.skip_connect_3_9(conv3)
        c8_9 = self.upsample8_9(conv8)
        c7_9 = self.upsample7_9(conv7)
        c6_9 = self.upsample6_9(conv6)
        x = torch.cat([c1_9, c2_9, c3_9, c8_9, c7_9, c6_9], dim=1)
        conv9 = self.dblock9(x)
        #第10个节点，1 down 2skip 3 4 5 6 up
        c1_10 = self.down1_10(conv1)
        c2_10 = self.skip_connect_2_10(conv2)
        c9_10 = self.upsample9_10(conv9)
        c8_10 = self.upsample8_10(conv8)
        c7_10 = self.upsample7_10(conv7)
        c6_10 = self.upsample6_10(conv6)
        x = torch.cat([c1_10, c2_10, c9_10, c8_10, c7_10, c6_10], dim=1)
        conv10 = self.dblock10(x)
        #第11个节点，1skip 2 3 4 5 6 up
        c1_11 = self.skip_connect_1_11(conv1)
        c10_11 = self.upsample10_11(conv10)
        c9_11 = self.upsample9_11(conv9)
        c8_11 = self.upsample8_11(conv8)
        c7_11 = self.upsample7_11(conv7)
        c6_11 = self.upsample6_11(conv6)
        x = torch.cat([c1_11, c10_11, c9_11, c8_11, c7_11, c6_11], dim=1)
        
        conv11 = self.dblock11(x)

        out = self.last_layer(conv11)
        return out

model = Unet().to(device)

learning_rate = 1e-3
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

best_model_path = 'bestmodel_unet.pt'

load_model,load_optimizer,load_checkpoint_epoch,load_valid_loss_min = load_ckp(best_model_path, model, optimizer)

def get_transforms(mean, std):
            list_transforms = []
            list_transforms.extend(
                    [
            Normalize(mean=mean, std=std, p=1),
            ToTensorV2(),
                    ])
            list_trfms = Compose(list_transforms)
            return list_trfms

# some utility functions
def mask_convert(mask):
    mask = mask.clone().cpu().detach().numpy()
    mask = mask.transpose((1,2,0))
    std = np.array((0.5))
    mean = np.array((0.5))
    mask  = std * mask + mean
    mask  = std * mask + mean
    mask = mask.clip(0,1)
    mask = np.squeeze(mask)
    return mask

# converting tensor to image
def image_convert(image):
    image = image.clone().cpu().numpy()
    image = image.transpose((1,2,0))
    std = np.array((0.5,0.5,0.5))
    mean = np.array((0.5,0.5,0.5))
    image  = std * image + mean
    image = image.clip(0,1)
    image = (image * 255).astype(np.uint8)
    return image

# 转二进制图像
def ToBinray(pred):
    ret, binary = cv2.threshold(pred, 127, 255, 0)
    return binary
    
#提取轮廓
def GetGontours2(binary,image):
    contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    dst = cv2.drawContours(image, contours, -1, (0, 255, 0), 2)
    return dst

def predict_img(image):
    image = image[:,:,:3].astype('float32')
    img = transform.resize(image,(256,256))
    store_image = img
    tran = get_transforms(0.5, 0.5)
    augmented = tran(image=img)
    img1 = augmented['image']
    img1 = img1.unsqueeze(0)
    im = torch.utils.data.DataLoader(dataset=img1, batch_size=1)
    iter_ = iter(im)
    image_read = next(iter_)
    image_read = image_read.to(device,dtype=torch.float)
    y_pred = load_model.forward(image_read)
    mask_predict = np.uint8(mask_convert(y_pred[0]))
    store_image = np.uint8(store_image)
    mask_predict = mask_predict * 255
    binary2 = ToBinray(mask_predict)
    dst2 = GetGontours2(binary2, store_image)
    return dst2
